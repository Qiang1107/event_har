 -----General Configuration------
 Epochs: 20
 Train batch size: 128
 Validation batch size: 128
 Test batch size: 32
 optim type: AdamW
 learning rate: 0.00025
 weight decay: 1e-2
 Model type: cnn
 Total model parameters: 16.88M
 Window_size: 9
 Stride: 3
 ------CNN Model Configuration------
 CNN Model: {'input_dim': 3, 'output_dim': 8, 'input_height': 128, 'input_width': 128}

[Epoch 1/20]
Train Loss: 1.8412
Training statistics: 7307 samples in 58 batches
Training time: 220.18 seconds
Val Loss: 1.7537, Val Acc: 0.3560
Validation statistics: 2612 samples in 21 batches
Validation time: 102.49 seconds
Learning rate: 0.000250

[Epoch 2/20]
Train Loss: 1.2185
Training statistics: 7307 samples in 58 batches
Training time: 224.27 seconds
Val Loss: 1.5513, Val Acc: 0.4609
Validation statistics: 2612 samples in 21 batches
Validation time: 99.74 seconds
Learning rate: 0.000250

[Epoch 3/20]
Train Loss: 0.8989
Training statistics: 7307 samples in 58 batches
Training time: 218.39 seconds
Val Loss: 1.4661, Val Acc: 0.5065
Validation statistics: 2612 samples in 21 batches
Validation time: 101.66 seconds
Learning rate: 0.000250

[Epoch 4/20]
Train Loss: 0.7142
Training statistics: 7307 samples in 58 batches
Training time: 221.27 seconds
Val Loss: 1.5225, Val Acc: 0.5322
Validation statistics: 2612 samples in 21 batches
Validation time: 99.22 seconds
Learning rate: 0.000250

[Epoch 5/20]
Train Loss: 0.5714
Training statistics: 7307 samples in 58 batches
Training time: 220.85 seconds
Val Loss: 1.5572, Val Acc: 0.5459
Validation statistics: 2612 samples in 21 batches
Validation time: 100.55 seconds
Learning rate: 0.000250

[Epoch 6/20]
Train Loss: 0.4673
Training statistics: 7307 samples in 58 batches
Training time: 218.64 seconds
Val Loss: 1.6120, Val Acc: 0.5459
Validation statistics: 2612 samples in 21 batches
Validation time: 100.51 seconds
Learning rate: 0.000250

[Epoch 7/20]
Train Loss: 0.4215
Training statistics: 7307 samples in 58 batches
Training time: 220.79 seconds
Val Loss: 1.6566, Val Acc: 0.5341
Validation statistics: 2612 samples in 21 batches
Validation time: 99.59 seconds
Learning rate: 0.000250

[Epoch 8/20]
Train Loss: 0.3581
Training statistics: 7307 samples in 58 batches
Training time: 219.24 seconds
Val Loss: 1.6715, Val Acc: 0.5513
Validation statistics: 2612 samples in 21 batches
Validation time: 100.30 seconds
Learning rate: 0.000250

[Epoch 9/20]
Train Loss: 0.3008
Training statistics: 7307 samples in 58 batches
Training time: 221.63 seconds
Val Loss: 1.7968, Val Acc: 0.5505
Validation statistics: 2612 samples in 21 batches
Validation time: 100.53 seconds
Learning rate: 0.000250

[Epoch 10/20]
Train Loss: 0.2845
Training statistics: 7307 samples in 58 batches
Training time: 219.47 seconds
Val Loss: 1.8649, Val Acc: 0.5126
Validation statistics: 2612 samples in 21 batches
Validation time: 99.84 seconds
Learning rate: 0.000025

[Epoch 11/20]
Train Loss: 0.1993
Training statistics: 7307 samples in 58 batches
Training time: 220.57 seconds
Val Loss: 1.8420, Val Acc: 0.5360
Validation statistics: 2612 samples in 21 batches
Validation time: 100.55 seconds
Learning rate: 0.000025

[Epoch 12/20]
Train Loss: 0.1914
Training statistics: 7307 samples in 58 batches
Training time: 217.46 seconds
Val Loss: 1.8805, Val Acc: 0.5379
Validation statistics: 2612 samples in 21 batches
Validation time: 101.07 seconds
Learning rate: 0.000025

[Epoch 13/20]
Train Loss: 0.1818
Training statistics: 7307 samples in 58 batches
Training time: 220.48 seconds
Val Loss: 1.9655, Val Acc: 0.5360
Validation statistics: 2612 samples in 21 batches
Validation time: 99.21 seconds
Learning rate: 0.000025

[Epoch 14/20]
Train Loss: 0.1795
Training statistics: 7307 samples in 58 batches
Training time: 219.26 seconds
Val Loss: 1.9419, Val Acc: 0.5421
Validation statistics: 2612 samples in 21 batches
Validation time: 101.46 seconds
Learning rate: 0.000025

[Epoch 15/20]
Train Loss: 0.1735
Training statistics: 7307 samples in 58 batches
Training time: 223.20 seconds
Val Loss: 1.9923, Val Acc: 0.5348
Validation statistics: 2612 samples in 21 batches
Validation time: 100.54 seconds
Learning rate: 0.000025

[Epoch 16/20]
Train Loss: 0.1694
Training statistics: 7307 samples in 58 batches
Training time: 219.98 seconds
Val Loss: 1.9611, Val Acc: 0.5402
Validation statistics: 2612 samples in 21 batches
Validation time: 100.37 seconds
Learning rate: 0.000025

[Epoch 17/20]
Train Loss: 0.1692
Training statistics: 7307 samples in 58 batches
Training time: 219.26 seconds
Val Loss: 1.9856, Val Acc: 0.5406
Validation statistics: 2612 samples in 21 batches
Validation time: 99.93 seconds
Learning rate: 0.000025

[Epoch 18/20]
Train Loss: 0.1613
Training statistics: 7307 samples in 58 batches
Training time: 220.29 seconds
Val Loss: 2.0481, Val Acc: 0.5333
Validation statistics: 2612 samples in 21 batches
Validation time: 100.78 seconds
Learning rate: 0.000025

[Epoch 19/20]
Train Loss: 0.1626
Training statistics: 7307 samples in 58 batches
Training time: 218.04 seconds
Val Loss: 2.0424, Val Acc: 0.5356
Validation statistics: 2612 samples in 21 batches
Validation time: 101.15 seconds
Learning rate: 0.000025

[Epoch 20/20]
Train Loss: 0.1583
Training statistics: 7307 samples in 58 batches
Training time: 215.62 seconds
Val Loss: 2.1021, Val Acc: 0.5337
Validation statistics: 2612 samples in 21 batches
Validation time: 101.27 seconds
Learning rate: 0.000003

[Test with best model from results/checkpoints/cnn_rgb_0628_8_1.pth]
Test statistics: 2614 samples in 82 batches
Test time: 315.45 seconds
Best validation accuracy: 0.5513016845329249
Test Acc: 0.5509 (1440/2614)
Per-class accuracy:
Approach: 0.4360 (160/367)
Pick_and_Place_Bolt: 0.5449 (170/312)
Pick_and_Place_Cover: 0.7846 (306/390)
Pick_and_Place_Part1_Small: 0.0220 (4/182)
Pick_and_Place_Part2_Big: 0.4246 (121/285)
Pick_and_Place_Screwdriver: 0.6150 (238/387)
Screw: 0.6762 (330/488)
Transition: 0.5468 (111/203)

Confusion Matrix:
160,44,6,27,10,5,0,115
26,170,12,0,8,12,0,84
35,16,306,9,14,0,0,10
41,0,0,4,90,0,0,47
73,14,0,56,121,2,0,19
23,4,16,0,0,238,101,5
0,0,0,0,0,158,330,0
49,12,7,2,19,3,0,111

Normalized Confusion Matrix:
0.44,0.12,0.02,0.07,0.03,0.01,0.00,0.31
0.08,0.54,0.04,0.00,0.03,0.04,0.00,0.27
0.09,0.04,0.78,0.02,0.04,0.00,0.00,0.03
0.23,0.00,0.00,0.02,0.49,0.00,0.00,0.26
0.26,0.05,0.00,0.20,0.42,0.01,0.00,0.07
0.06,0.01,0.04,0.00,0.00,0.61,0.26,0.01
0.00,0.00,0.00,0.00,0.00,0.32,0.68,0.00
0.24,0.06,0.03,0.01,0.09,0.01,0.00,0.55
