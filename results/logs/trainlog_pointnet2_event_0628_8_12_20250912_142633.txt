 -----General Configuration------
 Epochs: 30
 Train batch size: 16
 Validation batch size: 16
 Test batch size: 16
 optim type: AdamW
 learning rate: 0.0025
 weight decay: 1e-2
 Model type: pointnet2msg
 Total model parameters: 1.74M
 ------Pointnet2 Model Configuration------
 Loaded training data from: preprocessing_data/train_data_0628_8_ecount_4.pkl
 Pointnet2 Model: {'num_classes': 8, 'normal_channel': True, 'input_dim': 4}
 PointNet2Classifier source file: /mnt/portable/qqin/event_har/models/backbones/pointnet2_v1.py
 PointNet2MSGClassifier source file: /mnt/portable/qqin/event_har/models/backbones/pointnet2msg_v1.py
 pnet2_train_path: preprocessing_data/train_data_0628_8_ecount_4.pkl
 window_size_event_count: 8192
 step_size: 1024
 roi: False
 denoise: False
 denoise_method: voxel
 denoise_radius: 0.001
 voxel_size_txy: [8000, 4, 4]
 min_neighbors: 5
 denoise_threshold: 0.2

[Epoch 1/30]
Train Loss: 1.0556
Training statistics: 38270 samples in 2392 batches
Training time: 274.32 seconds
Val Loss: 0.5895, Val Acc: 0.7935
Validation statistics: 11638 samples in 728 batches
Validation time: 25.20 seconds
Learning rate: 0.002500

[Epoch 2/30]
Train Loss: 0.4425
Training statistics: 38270 samples in 2392 batches
Training time: 341.23 seconds
Val Loss: 0.5946, Val Acc: 0.8198
Validation statistics: 11638 samples in 728 batches
Validation time: 43.05 seconds
Learning rate: 0.002500

[Epoch 3/30]
Train Loss: 0.2980
Training statistics: 38270 samples in 2392 batches
Training time: 350.20 seconds
Val Loss: 0.4551, Val Acc: 0.8545
Validation statistics: 11638 samples in 728 batches
Validation time: 44.60 seconds
Learning rate: 0.002500

[Epoch 4/30]
Train Loss: 0.2261
Training statistics: 38270 samples in 2392 batches
Training time: 384.57 seconds
Val Loss: 0.3752, Val Acc: 0.8721
Validation statistics: 11638 samples in 728 batches
Validation time: 44.50 seconds
Learning rate: 0.002500

[Epoch 5/30]
Train Loss: 0.1786
Training statistics: 38270 samples in 2392 batches
Training time: 384.98 seconds
Val Loss: 0.4431, Val Acc: 0.8628
Validation statistics: 11638 samples in 728 batches
Validation time: 44.54 seconds
Learning rate: 0.002500

[Epoch 6/30]
Train Loss: 0.1533
Training statistics: 38270 samples in 2392 batches
Training time: 321.47 seconds
Val Loss: 0.2832, Val Acc: 0.9087
Validation statistics: 11638 samples in 728 batches
Validation time: 24.72 seconds
Learning rate: 0.002500

[Epoch 7/30]
Train Loss: 0.1332
Training statistics: 38270 samples in 2392 batches
Training time: 223.77 seconds
Val Loss: 0.3066, Val Acc: 0.9037
Validation statistics: 11638 samples in 728 batches
Validation time: 24.70 seconds
Learning rate: 0.002500

[Epoch 8/30]
Train Loss: 0.1172
Training statistics: 38270 samples in 2392 batches
Training time: 223.70 seconds
Val Loss: 0.4073, Val Acc: 0.8797
Validation statistics: 11638 samples in 728 batches
Validation time: 24.70 seconds
Learning rate: 0.002500

[Epoch 9/30]
Train Loss: 0.1072
Training statistics: 38270 samples in 2392 batches
Training time: 223.75 seconds
Val Loss: 0.2981, Val Acc: 0.9110
Validation statistics: 11638 samples in 728 batches
Validation time: 24.71 seconds
Learning rate: 0.002500

[Epoch 10/30]
Train Loss: 0.0982
Training statistics: 38270 samples in 2392 batches
Training time: 223.66 seconds
Val Loss: 0.2806, Val Acc: 0.9146
Validation statistics: 11638 samples in 728 batches
Validation time: 24.73 seconds
Learning rate: 0.000250

[Epoch 11/30]
Train Loss: 0.0437
Training statistics: 38270 samples in 2392 batches
Training time: 223.70 seconds
Val Loss: 0.2664, Val Acc: 0.9259
Validation statistics: 11638 samples in 728 batches
Validation time: 24.71 seconds
Learning rate: 0.000250

[Epoch 12/30]
Train Loss: 0.0286
Training statistics: 38270 samples in 2392 batches
Training time: 223.83 seconds
Val Loss: 0.2823, Val Acc: 0.9296
Validation statistics: 11638 samples in 728 batches
Validation time: 24.70 seconds
Learning rate: 0.000250

[Epoch 13/30]
Train Loss: 0.0231
Training statistics: 38270 samples in 2392 batches
Training time: 223.75 seconds
Val Loss: 0.2475, Val Acc: 0.9332
Validation statistics: 11638 samples in 728 batches
Validation time: 24.76 seconds
Learning rate: 0.000250

[Epoch 14/30]
Train Loss: 0.0194
Training statistics: 38270 samples in 2392 batches
Training time: 223.93 seconds
Val Loss: 0.3339, Val Acc: 0.9239
Validation statistics: 11638 samples in 728 batches
Validation time: 24.71 seconds
Learning rate: 0.000250

[Epoch 15/30]
Train Loss: 0.0172
Training statistics: 38270 samples in 2392 batches
Training time: 223.77 seconds
Val Loss: 0.3296, Val Acc: 0.9286
Validation statistics: 11638 samples in 728 batches
Validation time: 24.82 seconds
Learning rate: 0.000250

[Epoch 16/30]
Train Loss: 0.0179
Training statistics: 38270 samples in 2392 batches
Training time: 223.68 seconds
Val Loss: 0.3129, Val Acc: 0.9276
Validation statistics: 11638 samples in 728 batches
Validation time: 24.84 seconds
Learning rate: 0.000250

[Epoch 17/30]
Train Loss: 0.0149
Training statistics: 38270 samples in 2392 batches
Training time: 223.72 seconds
Val Loss: 0.3250, Val Acc: 0.9276
Validation statistics: 11638 samples in 728 batches
Validation time: 24.66 seconds
Learning rate: 0.000250

[Epoch 18/30]
Train Loss: 0.0125
Training statistics: 38270 samples in 2392 batches
Training time: 223.74 seconds
Val Loss: 0.3085, Val Acc: 0.9301
Validation statistics: 11638 samples in 728 batches
Validation time: 24.69 seconds
Learning rate: 0.000250

[Epoch 19/30]
Train Loss: 0.0121
Training statistics: 38270 samples in 2392 batches
Training time: 223.74 seconds
Val Loss: 0.3523, Val Acc: 0.9229
Validation statistics: 11638 samples in 728 batches
Validation time: 24.68 seconds
Learning rate: 0.000250

[Epoch 20/30]
Train Loss: 0.0125
Training statistics: 38270 samples in 2392 batches
Training time: 223.72 seconds
Val Loss: 0.3123, Val Acc: 0.9277
Validation statistics: 11638 samples in 728 batches
Validation time: 24.67 seconds
Learning rate: 0.000025

[Epoch 21/30]
Train Loss: 0.0089
Training statistics: 38270 samples in 2392 batches
Training time: 223.63 seconds
Val Loss: 0.3046, Val Acc: 0.9306
Validation statistics: 11638 samples in 728 batches
Validation time: 24.68 seconds
Learning rate: 0.000025

[Epoch 22/30]
Train Loss: 0.0095
Training statistics: 38270 samples in 2392 batches
Training time: 223.74 seconds
Val Loss: 0.3356, Val Acc: 0.9264
Validation statistics: 11638 samples in 728 batches
Validation time: 24.68 seconds
Learning rate: 0.000025

[Epoch 23/30]
Train Loss: 0.0081
Training statistics: 38270 samples in 2392 batches
Training time: 223.71 seconds
Val Loss: 0.3070, Val Acc: 0.9308
Validation statistics: 11638 samples in 728 batches
Validation time: 24.75 seconds
Learning rate: 0.000025

[Epoch 24/30]
Train Loss: 0.0076
Training statistics: 38270 samples in 2392 batches
Training time: 224.75 seconds
Val Loss: 0.3205, Val Acc: 0.9325
Validation statistics: 11638 samples in 728 batches
Validation time: 24.74 seconds
Learning rate: 0.000025

[Epoch 25/30]
Train Loss: 0.0083
Training statistics: 38270 samples in 2392 batches
Training time: 224.00 seconds
Val Loss: 0.3224, Val Acc: 0.9332
Validation statistics: 11638 samples in 728 batches
Validation time: 24.72 seconds
Learning rate: 0.000025

[Epoch 26/30]
Train Loss: 0.0069
Training statistics: 38270 samples in 2392 batches
Training time: 225.05 seconds
Val Loss: 0.3562, Val Acc: 0.9297
Validation statistics: 11638 samples in 728 batches
Validation time: 24.75 seconds
Learning rate: 0.000025

[Epoch 27/30]
Train Loss: 0.0078
Training statistics: 38270 samples in 2392 batches
Training time: 231.55 seconds
Val Loss: 0.3379, Val Acc: 0.9301
Validation statistics: 11638 samples in 728 batches
Validation time: 24.70 seconds
Learning rate: 0.000025

[Epoch 28/30]
Train Loss: 0.0059
Training statistics: 38270 samples in 2392 batches
Training time: 223.69 seconds
Val Loss: 0.3214, Val Acc: 0.9309
Validation statistics: 11638 samples in 728 batches
Validation time: 24.72 seconds
Learning rate: 0.000025

[Epoch 29/30]
Train Loss: 0.0074
Training statistics: 38270 samples in 2392 batches
Training time: 223.64 seconds
Val Loss: 0.3494, Val Acc: 0.9301
Validation statistics: 11638 samples in 728 batches
Validation time: 24.68 seconds
Learning rate: 0.000025

[Epoch 30/30]
Train Loss: 0.0081
Training statistics: 38270 samples in 2392 batches
Training time: 223.73 seconds
Val Loss: 0.3129, Val Acc: 0.9329
Validation statistics: 11638 samples in 728 batches
Validation time: 24.71 seconds
Learning rate: 0.000003

[Test with best model from results/checkpoints/pointnet2_event_0628_8_12.pth]
Test statistics: 13078 samples in 818 batches
Test time: 26.52 seconds
Best validation accuracy: 0.9332359511943633
Test Acc: 0.9680 (12659/13078)
Per-class accuracy:
Approach: 0.9791 (2954/3017)
Pick_and_Place_Bolt: 0.9363 (1043/1114)
Pick_and_Place_Cover: 0.9822 (1874/1908)
Pick_and_Place_Part1_Small: 0.9374 (794/847)
Pick_and_Place_Part2_Big: 0.9485 (1344/1417)
Pick_and_Place_Screwdriver: 0.9822 (2094/2132)
Screw: 0.9464 (742/784)
Transition: 0.9758 (1814/1859)

Confusion Matrix:
2954,0,12,10,0,3,1,37
0,1043,1,38,0,30,2,0
0,6,1874,0,27,1,0,0
8,18,0,794,6,21,0,0
0,7,11,55,1344,0,0,0
3,19,5,9,1,2094,0,1
0,18,0,0,3,21,742,0
33,2,0,9,0,1,0,1814

Normalized Confusion Matrix:
0.98,0.00,0.00,0.00,0.00,0.00,0.00,0.01
0.00,0.94,0.00,0.03,0.00,0.03,0.00,0.00
0.00,0.00,0.98,0.00,0.01,0.00,0.00,0.00
0.01,0.02,0.00,0.94,0.01,0.02,0.00,0.00
0.00,0.00,0.01,0.04,0.95,0.00,0.00,0.00
0.00,0.01,0.00,0.00,0.00,0.98,0.00,0.00
0.00,0.02,0.00,0.00,0.00,0.03,0.95,0.00
0.02,0.00,0.00,0.00,0.00,0.00,0.00,0.98
