 -----General Configuration------
 Epochs: 30
 Train batch size: 16
 Validation batch size: 16
 Test batch size: 16
 optim type: AdamW
 learning rate: 0.0025
 weight decay: 1e-2
 Model type: pointnet2msg
 Total model parameters: 1.74M
 ------Pointnet2 Model Configuration------
 Loaded training data from: preprocessing_data/train_data_0628_8_ecount_4.pkl
 Pointnet2 Model: {'num_classes': 8, 'normal_channel': True, 'input_dim': 4}
 PointNet2Classifier source file: /mnt/portable/qqin/event_har/models/backbones/pointnet2_v3.py
 PointNet2MSGClassifier source file: /mnt/portable/qqin/event_har/models/backbones/pointnet2msg_v3.py
 pnet2_train_path: preprocessing_data/train_data_0628_8_ecount_4.pkl
 window_size_event_count: 8192
 step_size: 1024
 roi: False
 denoise: False
 denoise_method: voxel
 denoise_radius: 0.001
 voxel_size_txy: [8000, 4, 4]
 min_neighbors: 5
 denoise_threshold: 0.2

[Epoch 1/30]
Train Loss: 1.0292
Training statistics: 38270 samples in 2392 batches
Training time: 398.03 seconds
Val Loss: 0.6796, Val Acc: 0.7536
Validation statistics: 11638 samples in 728 batches
Validation time: 34.93 seconds
Learning rate: 0.002500

[Epoch 2/30]
Train Loss: 0.4160
Training statistics: 38270 samples in 2392 batches
Training time: 293.52 seconds
Val Loss: 0.4490, Val Acc: 0.8446
Validation statistics: 11638 samples in 728 batches
Validation time: 26.49 seconds
Learning rate: 0.002500

[Epoch 3/30]
Train Loss: 0.2716
Training statistics: 38270 samples in 2392 batches
Training time: 354.32 seconds
Val Loss: 0.3840, Val Acc: 0.8681
Validation statistics: 11638 samples in 728 batches
Validation time: 46.36 seconds
Learning rate: 0.002500

[Epoch 4/30]
Train Loss: 0.2110
Training statistics: 38270 samples in 2392 batches
Training time: 321.09 seconds
Val Loss: 0.3999, Val Acc: 0.8728
Validation statistics: 11638 samples in 728 batches
Validation time: 25.08 seconds
Learning rate: 0.002500

[Epoch 5/30]
Train Loss: 0.1719
Training statistics: 38270 samples in 2392 batches
Training time: 338.25 seconds
Val Loss: 0.3011, Val Acc: 0.9002
Validation statistics: 11638 samples in 728 batches
Validation time: 35.02 seconds
Learning rate: 0.002500

[Epoch 6/30]
Train Loss: 0.1414
Training statistics: 38270 samples in 2392 batches
Training time: 357.41 seconds
Val Loss: 0.3415, Val Acc: 0.9021
Validation statistics: 11638 samples in 728 batches
Validation time: 25.13 seconds
Learning rate: 0.002500

[Epoch 7/30]
Train Loss: 0.1249
Training statistics: 38270 samples in 2392 batches
Training time: 346.65 seconds
Val Loss: 0.3935, Val Acc: 0.8914
Validation statistics: 11638 samples in 728 batches
Validation time: 34.95 seconds
Learning rate: 0.002500

[Epoch 8/30]
Train Loss: 0.1110
Training statistics: 38270 samples in 2392 batches
Training time: 343.60 seconds
Val Loss: 0.5443, Val Acc: 0.8425
Validation statistics: 11638 samples in 728 batches
Validation time: 25.16 seconds
Learning rate: 0.002500

[Epoch 9/30]
Train Loss: 0.0992
Training statistics: 38270 samples in 2392 batches
Training time: 311.98 seconds
Val Loss: 0.3861, Val Acc: 0.8713
Validation statistics: 11638 samples in 728 batches
Validation time: 30.46 seconds
Learning rate: 0.002500

[Epoch 10/30]
Train Loss: 0.0884
Training statistics: 38270 samples in 2392 batches
Training time: 349.03 seconds
Val Loss: 0.3541, Val Acc: 0.8975
Validation statistics: 11638 samples in 728 batches
Validation time: 34.03 seconds
Learning rate: 0.000250

[Epoch 11/30]
Train Loss: 0.0373
Training statistics: 38270 samples in 2392 batches
Training time: 318.73 seconds
Val Loss: 0.2493, Val Acc: 0.9290
Validation statistics: 11638 samples in 728 batches
Validation time: 33.62 seconds
Learning rate: 0.000250

[Epoch 12/30]
Train Loss: 0.0230
Training statistics: 38270 samples in 2392 batches
Training time: 363.42 seconds
Val Loss: 0.2555, Val Acc: 0.9344
Validation statistics: 11638 samples in 728 batches
Validation time: 35.02 seconds
Learning rate: 0.000250

[Epoch 13/30]
Train Loss: 0.0184
Training statistics: 38270 samples in 2392 batches
Training time: 362.03 seconds
Val Loss: 0.2560, Val Acc: 0.9345
Validation statistics: 11638 samples in 728 batches
Validation time: 33.83 seconds
Learning rate: 0.000250

[Epoch 14/30]
Train Loss: 0.0167
Training statistics: 38270 samples in 2392 batches
Training time: 339.27 seconds
Val Loss: 0.2668, Val Acc: 0.9275
Validation statistics: 11638 samples in 728 batches
Validation time: 34.09 seconds
Learning rate: 0.000250

[Epoch 15/30]
Train Loss: 0.0159
Training statistics: 38270 samples in 2392 batches
Training time: 335.18 seconds
Val Loss: 0.2694, Val Acc: 0.9347
Validation statistics: 11638 samples in 728 batches
Validation time: 32.92 seconds
Learning rate: 0.000250

[Epoch 16/30]
Train Loss: 0.0127
Training statistics: 38270 samples in 2392 batches
Training time: 351.87 seconds
Val Loss: 0.3233, Val Acc: 0.9271
Validation statistics: 11638 samples in 728 batches
Validation time: 35.61 seconds
Learning rate: 0.000250

[Epoch 17/30]
Train Loss: 0.0113
Training statistics: 38270 samples in 2392 batches
Training time: 319.27 seconds
Val Loss: 0.2932, Val Acc: 0.9350
Validation statistics: 11638 samples in 728 batches
Validation time: 25.11 seconds
Learning rate: 0.000250

[Epoch 18/30]
Train Loss: 0.0113
Training statistics: 38270 samples in 2392 batches
Training time: 265.83 seconds
Val Loss: 0.3042, Val Acc: 0.9314
Validation statistics: 11638 samples in 728 batches
Validation time: 25.08 seconds
Learning rate: 0.000250

[Epoch 19/30]
Train Loss: 0.0109
Training statistics: 38270 samples in 2392 batches
Training time: 432.19 seconds
Val Loss: 0.2787, Val Acc: 0.9350
Validation statistics: 11638 samples in 728 batches
Validation time: 52.23 seconds
Learning rate: 0.000250

[Epoch 20/30]
Train Loss: 0.0098
Training statistics: 38270 samples in 2392 batches
Training time: 583.94 seconds
Val Loss: 0.2741, Val Acc: 0.9337
Validation statistics: 11638 samples in 728 batches
Validation time: 56.31 seconds
Learning rate: 0.000025

[Epoch 21/30]
Train Loss: 0.0099
Training statistics: 38270 samples in 2392 batches
Training time: 569.36 seconds
Val Loss: 0.2698, Val Acc: 0.9345
Validation statistics: 11638 samples in 728 batches
Validation time: 55.72 seconds
Learning rate: 0.000025

[Epoch 22/30]
Train Loss: 0.0078
Training statistics: 38270 samples in 2392 batches
Training time: 582.94 seconds
Val Loss: 0.2640, Val Acc: 0.9368
Validation statistics: 11638 samples in 728 batches
Validation time: 56.88 seconds
Learning rate: 0.000025

[Epoch 23/30]
Train Loss: 0.0087
Training statistics: 38270 samples in 2392 batches
Training time: 557.75 seconds
Val Loss: 0.2615, Val Acc: 0.9397
Validation statistics: 11638 samples in 728 batches
Validation time: 48.11 seconds
Learning rate: 0.000025

[Epoch 24/30]
Train Loss: 0.0060
Training statistics: 38270 samples in 2392 batches
Training time: 321.83 seconds
Val Loss: 0.2813, Val Acc: 0.9365
Validation statistics: 11638 samples in 728 batches
Validation time: 25.32 seconds
Learning rate: 0.000025

[Epoch 25/30]
Train Loss: 0.0066
Training statistics: 38270 samples in 2392 batches
Training time: 266.15 seconds
Val Loss: 0.2668, Val Acc: 0.9358
Validation statistics: 11638 samples in 728 batches
Validation time: 25.15 seconds
Learning rate: 0.000025

[Epoch 26/30]
Train Loss: 0.0063
Training statistics: 38270 samples in 2392 batches
Training time: 402.08 seconds
Val Loss: 0.2876, Val Acc: 0.9361
Validation statistics: 11638 samples in 728 batches
Validation time: 37.40 seconds
Learning rate: 0.000025

[Epoch 27/30]
Train Loss: 0.0059
Training statistics: 38270 samples in 2392 batches
Training time: 458.01 seconds
Val Loss: 0.2867, Val Acc: 0.9357
Validation statistics: 11638 samples in 728 batches
Validation time: 48.27 seconds
Learning rate: 0.000025

[Epoch 28/30]
Train Loss: 0.0068
Training statistics: 38270 samples in 2392 batches
Training time: 446.75 seconds
Val Loss: 0.2619, Val Acc: 0.9408
Validation statistics: 11638 samples in 728 batches
Validation time: 48.24 seconds
Learning rate: 0.000025

[Epoch 29/30]
Train Loss: 0.0070
Training statistics: 38270 samples in 2392 batches
Training time: 446.96 seconds
Val Loss: 0.2742, Val Acc: 0.9371
Validation statistics: 11638 samples in 728 batches
Validation time: 48.24 seconds
Learning rate: 0.000025

[Epoch 30/30]
Train Loss: 0.0048
Training statistics: 38270 samples in 2392 batches
Training time: 468.41 seconds
Val Loss: 0.2782, Val Acc: 0.9378
Validation statistics: 11638 samples in 728 batches
Validation time: 27.22 seconds
Learning rate: 0.000003

[Test with best model from results/checkpoints/pointnet2_event_0628_8_21.pth]
Test statistics: 13078 samples in 818 batches
Test time: 53.03 seconds
Best validation accuracy: 0.9407973878673311
Test Acc: 0.9747 (12747/13078)
Per-class accuracy:
Approach: 0.9794 (2955/3017)
Pick_and_Place_Bolt: 0.9533 (1062/1114)
Pick_and_Place_Cover: 0.9879 (1885/1908)
Pick_and_Place_Part1_Small: 0.8985 (761/847)
Pick_and_Place_Part2_Big: 0.9633 (1365/1417)
Pick_and_Place_Screwdriver: 0.9859 (2102/2132)
Screw: 0.9732 (763/784)
Transition: 0.9973 (1854/1859)

Confusion Matrix:
2955,3,14,1,0,26,0,18
0,1062,6,16,3,25,2,0
0,5,1885,0,17,1,0,0
10,10,0,761,33,33,0,0
0,15,11,26,1365,0,0,0
8,12,2,6,0,2102,2,0
0,19,0,0,0,2,763,0
2,0,0,0,0,3,0,1854

Normalized Confusion Matrix:
0.98,0.00,0.00,0.00,0.00,0.01,0.00,0.01
0.00,0.95,0.01,0.01,0.00,0.02,0.00,0.00
0.00,0.00,0.99,0.00,0.01,0.00,0.00,0.00
0.01,0.01,0.00,0.90,0.04,0.04,0.00,0.00
0.00,0.01,0.01,0.02,0.96,0.00,0.00,0.00
0.00,0.01,0.00,0.00,0.00,0.99,0.00,0.00
0.00,0.02,0.00,0.00,0.00,0.00,0.97,0.00
0.00,0.00,0.00,0.00,0.00,0.00,0.00,1.00
